{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1L3l1Alfk8bVVT0psD_H4cAav8PGHkpnV",
      "authorship_tag": "ABX9TyMG3nGaxMWzizGUDNentX5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minanayernia/MSc_Thesis/blob/master/Thesis_part2_generate_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwx26e8nyQIh",
        "outputId": "0ca96518-a7b2-4430-8260-d7d46d2c4d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6B1mKtJ2-dc",
        "outputId": "6ba53526-5bce-4569-e36f-f4cfd1edcc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
        "\n",
        "def generate_embeddings(file):\n",
        "    df = pd.read_csv(file)\n",
        "    df[\"embeddings\"] = None\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        text = row[\"LLM_reason\"]\n",
        "\n",
        "        # Skip if the text is NaN or not a string\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            continue\n",
        "\n",
        "        embedding = model.encode(text)\n",
        "        df.at[index, \"embeddings\"] = embedding.tolist()\n",
        "\n",
        "    df.to_csv(file, index=False)\n"
      ],
      "metadata": {
        "id": "UybdVPQH2BWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "embeddings of GPT role_baseds"
      ],
      "metadata": {
        "id": "DjGYwqyy3db5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/America_GPT.csv\")"
      ],
      "metadata": {
        "id": "IZzk_Ivs3PLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/China_GPT.csv\")"
      ],
      "metadata": {
        "id": "bI8pUO0aPFNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/France_GPT.csv\")"
      ],
      "metadata": {
        "id": "b-lsgvOjPK2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Germany_GPT.csv\")"
      ],
      "metadata": {
        "id": "uSathvYwPR9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Iran_GPT.csv\")"
      ],
      "metadata": {
        "id": "0yBrKljPPYqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Israel_GPT.csv\")"
      ],
      "metadata": {
        "id": "_uH_pa4iPcgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Italy_GPT.csv\")"
      ],
      "metadata": {
        "id": "MhgKo1DbPcU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Russia_GPT.csv\")"
      ],
      "metadata": {
        "id": "-J3a8_cnPcI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Ukraine_GPT.csv\")"
      ],
      "metadata": {
        "id": "UrlY-E1uPqXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/without_role_LLM_answers.csv\")"
      ],
      "metadata": {
        "id": "uZ-pAWERP0td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings of GPT natives"
      ],
      "metadata": {
        "id": "e98kC5EfT49x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/America_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "3bIPqpEpUBtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
        "\n",
        "def generate_embeddings_native(file):\n",
        "    df = pd.read_csv(file)\n",
        "    df[\"embeddings\"] = None\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        text = row[\"LLM_Reason_native\"]\n",
        "\n",
        "        # Skip if the text is NaN or not a string\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            continue\n",
        "\n",
        "        embedding = model.encode(text)\n",
        "        df.at[index, \"embeddings\"] = embedding.tolist()\n",
        "\n",
        "    df.to_csv(file, index=False)\n"
      ],
      "metadata": {
        "id": "vPpfAjM_Ym1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/China_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "GKe7ahJ1XPXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/France_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "tBRYeUt2XPUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Germany_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "jTM-jQ0mXPRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Iran_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "hFlE-uRPXPOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Israel_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "Sa9GRouJXPMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Italy_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "kaSBU2LSXPJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Russia_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "43VKLiafXPGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Ukraine_GPT_native.csv\")"
      ],
      "metadata": {
        "id": "xoZYuJgJXO8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings of LLama role_based"
      ],
      "metadata": {
        "id": "_DkAaj3HYRBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/America_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "9sHqzVu3ZFqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/China_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "mc7PpibxZffi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/France_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "lOPgyPepZsqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Germany_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "xszvfwbTZsnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Iran_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "9Jm2rSh-ZuXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Israel_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "ILlRFFIFZsky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Italy_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "e0jcjlL-ZsiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Russia_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "l4FlqkDtZsfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/Ukraine_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "rPRh23RXZscw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings(\"/content/drive/MyDrive/without_role_Llama_answers.csv\")"
      ],
      "metadata": {
        "id": "jV1FuSWrZsTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings of LLama native"
      ],
      "metadata": {
        "id": "09Ziy1ZNhggU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/America_llama_native.csv\")"
      ],
      "metadata": {
        "id": "OoIVkBrwZrnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/China_llama_native.csv\")"
      ],
      "metadata": {
        "id": "Ecrif7WGh3Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/France_llama_native.csv\")"
      ],
      "metadata": {
        "id": "sKyluJYSh3Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Germany_llama_native.csv\")"
      ],
      "metadata": {
        "id": "MjYnYgUCh27Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Iran_llama_native.csv\")"
      ],
      "metadata": {
        "id": "JGoB7oDZiD_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Israel_llama_native.csv\")"
      ],
      "metadata": {
        "id": "-iw3S6hFiBzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Italy_llama_native.csv\")"
      ],
      "metadata": {
        "id": "lCGE4cBNiBqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Russia_llama_native.csv\")"
      ],
      "metadata": {
        "id": "oRwccw_5iBhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_embeddings_native(\"/content/drive/MyDrive/Ukraine_llama_native.csv\")"
      ],
      "metadata": {
        "id": "mmiwWHMxiBZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wikipedia"
      ],
      "metadata": {
        "id": "4if3JmulWxCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Ce9wvXWwkU",
        "outputId": "53e6e401-567c-4b6b-e734-08efa9fdf48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2025.4.26)\n",
            "Building wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=8c5cfb45ade5eb30e38af775717fbafc7a13340c62003cefc753fe605acd0b7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia-api googletrans==4.0.0-rc1 pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHUrYlRNXNKP",
        "outputId": "6f8f95fd-4bf8-422d-80e1-85126e01fb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.4.26)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.4.0)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=d0129cf227a9463a0d989bfe25d196a8dd0f5dc3550cca511c78a77a5cd64583\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: hyperframe\n",
            "    Found existing installation: hyperframe 6.1.0\n",
            "    Uninstalling hyperframe-6.1.0:\n",
            "      Successfully uninstalled hyperframe-6.1.0\n",
            "  Attempting uninstall: hpack\n",
            "    Found existing installation: hpack 4.1.0\n",
            "    Uninstalling hpack-4.1.0:\n",
            "      Successfully uninstalled hpack-4.1.0\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: h2\n",
            "    Found existing installation: h2 4.2.0\n",
            "    Uninstalling h2-4.2.0:\n",
            "      Successfully uninstalled h2-4.2.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.17.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.13.3 which is incompatible.\n",
            "langsmith 0.3.43 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio 5.31.0 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n",
            "openai 1.82.1 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio-client 1.10.1 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from googletrans import Translator\n",
        "import wikipediaapi\n",
        "import time\n",
        "\n",
        "# Topics in English\n",
        "map_topics = [\n",
        "    (3, \"We should fight for the abolition of nuclear weapons\", \"Nuclear weapons\"),\n",
        "    (4, \"We should legalize sex selection\", \"Sex selection\"),\n",
        "    (15, \"We should end the use of economic sanctions\", \"Economic sanctions\"),\n",
        "    (17, \"We should legalize prostitution\", \"Prostitution\"),\n",
        "    (18, \"We should adopt a multi-party system\", \"Multi-party system\"),\n",
        "    (22, \"We should adopt atheism\", \"Atheism\"),\n",
        "    (36, \"We should introduce compulsory voting\", \"Compulsory voting\"),\n",
        "    (40, \"We should adopt libertarianism\", \"Libertarianism\"),\n",
        "    (50, \"We should ban the Church of Scientology\", \"Church of Scientology\")\n",
        "]\n",
        "\n",
        "# Target languages (fixed: 'zh-CN' → 'zh')\n",
        "languages = {\n",
        "    'en': 'English',\n",
        "    'fr': 'French',\n",
        "    'de': 'German',\n",
        "    'ru': 'Russian',\n",
        "    'uk': 'Ukrainian',\n",
        "    'fa': 'Persian',\n",
        "    'he': 'Hebrew',\n",
        "    'zh': 'Chinese'\n",
        "}\n",
        "\n",
        "USER_AGENT = \"LLM-bias-study/1.0 (mina.nayernia@student.unimi.it)\"\n",
        "translator = Translator()\n",
        "data = []\n",
        "\n",
        "for topic_id, full_topic, topic_keyword in map_topics:\n",
        "    print(f\"\\n🔍 Processing Topic: {topic_keyword}\")\n",
        "    for lang_code, lang_name in languages.items():\n",
        "        wiki = wikipediaapi.Wikipedia(language=lang_code, user_agent=USER_AGENT)\n",
        "\n",
        "        try:\n",
        "            # Translate only if not English\n",
        "            translated_title = topic_keyword\n",
        "            if lang_code != 'en':\n",
        "                try:\n",
        "                    translated_title = translator.translate(topic_keyword, dest=lang_code).text\n",
        "                    time.sleep(0.5)  # avoid hitting limits\n",
        "                except Exception as te:\n",
        "                    print(f\"⚠️ Translation failed for {lang_name}: {te}\")\n",
        "                    translated_title = topic_keyword  # fallback to English title\n",
        "\n",
        "            print(f\"🌐 {lang_name} - Searching: {translated_title}\")\n",
        "            page = wiki.page(translated_title)\n",
        "\n",
        "            # Fallback to English title if translation fails\n",
        "            if not page.exists() and lang_code != 'en':\n",
        "                print(f\"🔁 Fallback to English title: {topic_keyword}\")\n",
        "                page = wiki.page(topic_keyword)\n",
        "\n",
        "            if page.exists():\n",
        "                summary = page.summary\n",
        "                print(f\"✅ Found page in {lang_name}\")\n",
        "            else:\n",
        "                summary = \"\"\n",
        "                print(f\"❌ Page not found in {lang_name}\")\n",
        "\n",
        "            data.append({\n",
        "                \"topic_id\": topic_id,\n",
        "                \"original_topic\": topic_keyword,\n",
        "                \"language\": lang_code,\n",
        "                \"language_name\": lang_name,\n",
        "                \"translated_title\": translated_title,\n",
        "                \"summary\": summary\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"🚫 Error with {lang_name}: {e}\")\n",
        "            data.append({\n",
        "                \"topic_id\": topic_id,\n",
        "                \"original_topic\": topic_keyword,\n",
        "                \"language\": lang_code,\n",
        "                \"language_name\": lang_name,\n",
        "                \"translated_title\": \"ERROR\",\n",
        "                \"summary\": \"\"\n",
        "            })\n",
        "\n",
        "        time.sleep(1.5)  # polite delay\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"wikipedia_topic_summaries.csv\", index=False)\n",
        "print(\"\\n📄 Data saved to wikipedia_topic_summaries.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcmRsPYoiA0b",
        "outputId": "208f7a07-1e74-4fff-955a-e054a41b6135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Processing Topic: Nuclear weapons\n",
            "🌐 English - Searching: Nuclear weapons\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Armes nucléaires\n",
            "✅ Found page in French\n",
            "🌐 German - Searching: Atomwaffen\n",
            "✅ Found page in German\n",
            "🌐 Russian - Searching: Ядерное оружие\n",
            "✅ Found page in Russian\n",
            "🌐 Ukrainian - Searching: Ядерна зброя\n",
            "✅ Found page in Ukrainian\n",
            "🌐 Persian - Searching: سلاح های هسته ای\n",
            "✅ Found page in Persian\n",
            "🌐 Hebrew - Searching: נשק גרעיני\n",
            "✅ Found page in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Nuclear weapons\n",
            "🔁 Fallback to English title: Nuclear weapons\n",
            "❌ Page not found in Chinese\n",
            "\n",
            "🔍 Processing Topic: Sex selection\n",
            "🌐 English - Searching: Sex selection\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Sélection sexuelle\n",
            "✅ Found page in French\n",
            "🌐 German - Searching: Geschlechtsauswahl\n",
            "🔁 Fallback to English title: Sex selection\n",
            "❌ Page not found in German\n",
            "🌐 Russian - Searching: Выбор пола\n",
            "🔁 Fallback to English title: Sex selection\n",
            "❌ Page not found in Russian\n",
            "🌐 Ukrainian - Searching: Вибір статі\n",
            "🔁 Fallback to English title: Sex selection\n",
            "❌ Page not found in Ukrainian\n",
            "🌐 Persian - Searching: انتخاب جنسی\n",
            "✅ Found page in Persian\n",
            "🌐 Hebrew - Searching: בחירת מין\n",
            "✅ Found page in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Sex selection\n",
            "🔁 Fallback to English title: Sex selection\n",
            "❌ Page not found in Chinese\n",
            "\n",
            "🔍 Processing Topic: Economic sanctions\n",
            "🌐 English - Searching: Economic sanctions\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Sanctions économiques\n",
            "✅ Found page in French\n",
            "🌐 German - Searching: Wirtschaftssanktionen\n",
            "✅ Found page in German\n",
            "🌐 Russian - Searching: Экономические санкции\n",
            "✅ Found page in Russian\n",
            "🌐 Ukrainian - Searching: Економічні санкції\n",
            "✅ Found page in Ukrainian\n",
            "🌐 Persian - Searching: تحریم های اقتصادی\n",
            "🔁 Fallback to English title: Economic sanctions\n",
            "❌ Page not found in Persian\n",
            "🌐 Hebrew - Searching: סנקציות כלכליות\n",
            "🔁 Fallback to English title: Economic sanctions\n",
            "❌ Page not found in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Economic sanctions\n",
            "🔁 Fallback to English title: Economic sanctions\n",
            "❌ Page not found in Chinese\n",
            "\n",
            "🔍 Processing Topic: Prostitution\n",
            "🌐 English - Searching: Prostitution\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Prostitution\n",
            "✅ Found page in French\n",
            "🌐 German - Searching: Prostitution\n",
            "✅ Found page in German\n",
            "🌐 Russian - Searching: Проституция\n",
            "✅ Found page in Russian\n",
            "🌐 Ukrainian - Searching: Проституція\n",
            "✅ Found page in Ukrainian\n",
            "🌐 Persian - Searching: فحشا\n",
            "✅ Found page in Persian\n",
            "🌐 Hebrew - Searching: זְנוּת\n",
            "🔁 Fallback to English title: Prostitution\n",
            "❌ Page not found in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Prostitution\n",
            "✅ Found page in Chinese\n",
            "\n",
            "🔍 Processing Topic: Multi-party system\n",
            "🌐 English - Searching: Multi-party system\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Système multipartite\n",
            "🔁 Fallback to English title: Multi-party system\n",
            "❌ Page not found in French\n",
            "🌐 German - Searching: Mehrparteiensystem\n",
            "✅ Found page in German\n",
            "🌐 Russian - Searching: Многопартийная система\n",
            "✅ Found page in Russian\n",
            "🌐 Ukrainian - Searching: Багатопартійна система\n",
            "✅ Found page in Ukrainian\n",
            "🌐 Persian - Searching: سیستم چند جانبه\n",
            "🔁 Fallback to English title: Multi-party system\n",
            "❌ Page not found in Persian\n",
            "🌐 Hebrew - Searching: מערכת רב מפלגתית\n",
            "✅ Found page in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Multi-party system\n",
            "🔁 Fallback to English title: Multi-party system\n",
            "❌ Page not found in Chinese\n",
            "\n",
            "🔍 Processing Topic: Atheism\n",
            "🌐 English - Searching: Atheism\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Athéisme\n",
            "✅ Found page in French\n",
            "🌐 German - Searching: Atheismus\n",
            "✅ Found page in German\n",
            "🌐 Russian - Searching: Атеизм\n",
            "✅ Found page in Russian\n",
            "🌐 Ukrainian - Searching: Атеїзм\n",
            "✅ Found page in Ukrainian\n",
            "🌐 Persian - Searching: الحاد\n",
            "✅ Found page in Persian\n",
            "🌐 Hebrew - Searching: אתאיזם\n",
            "✅ Found page in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Atheism\n",
            "✅ Found page in Chinese\n",
            "\n",
            "🔍 Processing Topic: Compulsory voting\n",
            "🌐 English - Searching: Compulsory voting\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Vote obligatoire\n",
            "✅ Found page in French\n",
            "🌐 German - Searching: Obligatorische Abstimmung\n",
            "🔁 Fallback to English title: Compulsory voting\n",
            "❌ Page not found in German\n",
            "🌐 Russian - Searching: Обязательное голосование\n",
            "✅ Found page in Russian\n",
            "🌐 Ukrainian - Searching: Обов’язкове голосування\n",
            "🔁 Fallback to English title: Compulsory voting\n",
            "❌ Page not found in Ukrainian\n",
            "🌐 Persian - Searching: رای گیری اجباری\n",
            "🔁 Fallback to English title: Compulsory voting\n",
            "❌ Page not found in Persian\n",
            "🌐 Hebrew - Searching: הצבעה חובה\n",
            "🔁 Fallback to English title: Compulsory voting\n",
            "❌ Page not found in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Compulsory voting\n",
            "🔁 Fallback to English title: Compulsory voting\n",
            "❌ Page not found in Chinese\n",
            "\n",
            "🔍 Processing Topic: Libertarianism\n",
            "🌐 English - Searching: Libertarianism\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Libertarisme\n",
            "✅ Found page in French\n",
            "🌐 German - Searching: Libertarismus\n",
            "✅ Found page in German\n",
            "🌐 Russian - Searching: Либертарианство\n",
            "✅ Found page in Russian\n",
            "🌐 Ukrainian - Searching: Лібертаріанство\n",
            "✅ Found page in Ukrainian\n",
            "🌐 Persian - Searching: آزادی گرایی\n",
            "✅ Found page in Persian\n",
            "🌐 Hebrew - Searching: ליברטריזם\n",
            "🔁 Fallback to English title: Libertarianism\n",
            "❌ Page not found in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Libertarianism\n",
            "🔁 Fallback to English title: Libertarianism\n",
            "❌ Page not found in Chinese\n",
            "\n",
            "🔍 Processing Topic: Church of Scientology\n",
            "🌐 English - Searching: Church of Scientology\n",
            "✅ Found page in English\n",
            "🌐 French - Searching: Église de Scientologie\n",
            "✅ Found page in French\n",
            "🌐 German - Searching: Scientology Church\n",
            "✅ Found page in German\n",
            "🌐 Russian - Searching: Церковь саентологии\n",
            "✅ Found page in Russian\n",
            "🌐 Ukrainian - Searching: Церква саєнтології\n",
            "✅ Found page in Ukrainian\n",
            "🌐 Persian - Searching: کلیسای علم شناسی\n",
            "🔁 Fallback to English title: Church of Scientology\n",
            "❌ Page not found in Persian\n",
            "🌐 Hebrew - Searching: כנסיית הסיינטולוגיה\n",
            "✅ Found page in Hebrew\n",
            "⚠️ Translation failed for Chinese: invalid destination language\n",
            "🌐 Chinese - Searching: Church of Scientology\n",
            "✅ Found page in Chinese\n",
            "\n",
            "📄 Data saved to wikipedia_topic_summaries.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load LaBSE model (supports over 100 languages)\n",
        "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
        "\n",
        "def add_summary_embeddings(csv_path):\n",
        "    # Load the CSV\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Ensure there's a \"summary\" column\n",
        "    if \"summary\" not in df.columns:\n",
        "        raise ValueError(\"The input CSV must contain a 'summary' column.\")\n",
        "\n",
        "    # Replace NaNs with empty string (to avoid errors in model.encode)\n",
        "    df[\"summary\"] = df[\"summary\"].fillna(\"\")\n",
        "\n",
        "    # Initialize the 'embedding' column as a list of None or empty lists\n",
        "    df[\"embedding\"] = None\n",
        "\n",
        "    # Compute and assign embeddings to each row in the 'embedding' column\n",
        "    for index, row in df.iterrows():\n",
        "        embedding = model.encode(row[\"summary\"]).tolist()\n",
        "        df.at[index, \"embedding\"] = embedding\n",
        "\n",
        "    # Save back to file\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"✅ Embeddings saved to: {csv_path}\")\n",
        "\n",
        "# Example usage\n",
        "add_summary_embeddings(\"/content/drive/MyDrive/wikipedia_topic_summaries.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wSqA4zIYJXf",
        "outputId": "31ce2ffd-4f6e-41fb-d552-502f6167fccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embeddings saved to: /content/drive/MyDrive/wikipedia_topic_summaries.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9111m454awTe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}